{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expected-sunglasses",
   "metadata": {},
   "source": [
    "![image](https://hydro-jules.org/sites/default/files/Hydro-JULES_Logo_Positive.png)\n",
    "# Hydro-JULES - Plotting observed data against modelled data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-placement",
   "metadata": {},
   "source": [
    "This notebook provides a very basic walk through of how to use observed data in csv format (from COSMOS-UK network) and compare it against modelled gridded soil moisture data in netCDF format (created for Hydro-JULES), in python using the Numpy, Cf-Python and Matplotlib packages.\n",
    "\n",
    "For an introduction of the tutorial please see the video https://youtu.be/kqez7RtCKdk\n",
    "\n",
    "The observed data used in this example is the volumentric water content (VWC) from COSMOS UK station network. VWC is the percentage water content of the soil. This is measured by the COSMOS stations (https://cosmos.ceh.ac.uk/) and is driven by the balance between precipitation and evaporation. The modelled data used in this example is soil water stress (SWS). SWS is a dimensionless variable typically used to determine how much soil moisture vegetation has access to for transpiration. It is modelled using the Artemis Model (https://github.com/cm4twc-org/cm4twccontrib-artemis), where it is calculated using the soil water content.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-craps",
   "metadata": {},
   "source": [
    "**Contents** (note: to run cells later in the notebook, the first few cells must be run in order to import packages and initialise variables):\n",
    "- [Import packages required for this work](#import_packages)\n",
    "- [Quick csv and netCDF file access to show how easy it is](#quick_file_access)\n",
    "- [Reading the data into different numpy arrays](#explore_data)\n",
    "- [Quick plotting of data](#quick_plot_data)\n",
    "- [Manipulating the datasets](#manipulating_data)\n",
    "- [Further exercises](#further_exercises)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-growth",
   "metadata": {},
   "source": [
    "<a id=\"import_packages\"></a>\n",
    "### Import packages required for this work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing cf-python and cfplot\n",
    "import cf, cfplot as cfp\n",
    "\n",
    "# Additional packages for advance plotting with cfplot\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Importing matplotlib to show that data read through cf-python can be plotted using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Importing numpy\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "# The following line allows matplotlib plots to be shown in the notebook\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-reflection",
   "metadata": {},
   "source": [
    "<a id=\"quick_file_access\"></a>\n",
    "### Quick csv and NetCDF file access to show how easy it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the data path and add file name\n",
    "path = '/data/example-data/'\n",
    "fsite = 'SITES_2016.csv'\n",
    "\n",
    "# Read the station information csv file using numpy\n",
    "my_stations = np.genfromtxt(path+fsite, delimiter=',', dtype='unicode') # Unicode reads data in string type which would need to be converted to float later on\n",
    "\n",
    "# Printing the dataset read in as a check\n",
    "print(my_stations)\n",
    "# Columns show site_id, site_name, latitude and longitude and rows show each station information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the VWC data csv file using numpy\n",
    "fcos = 'COSMOS_VWC_2016.csv'\n",
    "my_vwc = np.genfromtxt(path+fcos, delimiter=',', dtype='unicode')\n",
    "# Instead of this you can also use my_vwc = np.genfromtxt(path+fcos, delimiter=',', skip_header=1) to remove the header and just have floats\n",
    "# Pandas is also a good python package to be able to use for csv tables. Currently it is not installed in DataLabs.\n",
    "\n",
    "# Printing the dataset read in as a check\n",
    "print(my_vwc)\n",
    "print(my_vwc.shape) \n",
    "# There are 366 days information in rows with one extra row for the titles. There are 30 stations and one extra column for time information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating separate arrays for Station IDs, Names, latitudes and Longitudes without the headings\n",
    "st_id = my_stations[1:,0]\n",
    "st_name = my_stations[1:,1]\n",
    "st_lat = my_stations[1:,2]\n",
    "st_lon = my_stations[1:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a file name along with its path\n",
    "path = '/data/demo-data/out-example/'\n",
    "file = 'demo-run-more-records_subsurface_run_records_daily.nc'\n",
    "\n",
    "# We read in a netCDF file from the modelled output and select the soil water stress (SWS) variable\n",
    "my_sws = cf.read(path+file).select('soil_water_stress')[0]\n",
    "\n",
    "# To convert the SWC to similar units of VWC, we multiply SWC with 100\n",
    "my_sws = my_sws*100\n",
    "print(my_sws)\n",
    "\n",
    "# Time mean for the SWS data\n",
    "my_sws_mean = my_sws.collapse('time: mean').squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-dealing",
   "metadata": {},
   "source": [
    "<a id=\"quick_plot_data\"></a>\n",
    "### Quick plotting of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cf-plot is the plotting software for cfpython\n",
    "cfp.reset() # Just to reset any old settings for cfplot\n",
    "\n",
    "#Plotting all the stations on a UK map\n",
    "cfp.gopen()\n",
    "cfp.mapset(latmin=49, latmax=60, lonmin=-11, lonmax=2, resolution='50m') #This line is for improved resolution than default of 110m\n",
    "cfp.setvars(continent_thickness=0.5) #continent_thickness is for thinner continent outline than default of 1.5\n",
    "cfp.levs(min=0,max=100,step=10)\n",
    "cfp.cscale('WhiteBlue')\n",
    "cfp.con(my_sws_mean, lines=False, blockfill=True, colorbar_title='') # We have made sure that both contour lines and shading are switched off to have just outline map of UK\n",
    "for i in range(len(st_name)):\n",
    "    cfp.plotvars.mymap.plot(float(st_lon[i]),float(st_lat[i]), linewidth=3.0, marker='o', color='red', transform=ccrs.PlateCarree())\n",
    "    cfp.plotvars.mymap.text(float(st_lon[i])-0.2,float(st_lat[i])+0.05, st_id[i], color='red',fontsize=8, horizontalalignment='center', transform=ccrs.PlateCarree())\n",
    "\n",
    "cfp.gclose()\n",
    "\n",
    "# cfp.con refers to contour plots, for more types of plots please see http://ajheaps.github.io/cf-plot/gallery.html\n",
    "# my_dataset[0,:,:] uses subspacing by index, for more detail please see https://ncas-cms.github.io/cf-python/tutorial.html?#subspacing-by-index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-dynamics",
   "metadata": {},
   "source": [
    "<a id=\"manipulating_data\"></a>\n",
    "### Manipulating the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We learn how to select specific station data for the whole 366 days of the leap year as an numpy array\n",
    "# For example, we would like to compare the two northermost stations, \"ALIC1\", against the nearest station \"CHOBH\"\n",
    "# To find the station data from just the name, we need to find the index for the station in the first row of my_vwc\n",
    "print(my_vwc[0,:]) # First row of my_vwc\n",
    "# Please note that each station id has \"_VWC\" at the end, so we need to add that in the query to find the index for the respective station\n",
    "#For example, to find station \"ALIC1\" index, we need to search for \"ALIC1_VWC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to find the index for station ALIC1 and CHOBH from the station data\n",
    "alic1_idx = np.where(my_vwc[0,:]=='ALIC1_VWC')[0][0]\n",
    "chobh_idx = np.where(my_vwc[0,:]=='CHOBH_VWC')[0][0]\n",
    "print('Index for ALIC1 station is '+str(alic1_idx))\n",
    "print('Index for CHOBH station is '+str(chobh_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the indices for the stations fromt the cell above we can extract data for both of the stations\n",
    "alic1_vwc = my_vwc[1:,alic1_idx].tolist() # We use 1: to remove the station name from the list and tolist to convert to list\n",
    "print(alic1_vwc) # All the data is in string format, which we will convert to float and use NaN values for empty strings\n",
    "alic1_vwc = np.array([np.nan if x == '' else float(x) for x in alic1_vwc]) # We use list conversion to change the strings to float\n",
    "print(alic1_vwc)\n",
    "print(alic1_vwc.shape)\n",
    "\n",
    "# We do the same for CHOBH station VWC data\n",
    "chobh_vwc = my_vwc[1:,chobh_idx].tolist()\n",
    "chobh_vwc = np.array([np.nan if x == '' else float(x) for x in chobh_vwc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying the model grid point nearest to the ALIC1 and CHOBH stations\n",
    "# First step is to find the latitude and longitude for the two stations\n",
    "alic1_idx = np.where(my_stations=='ALIC1')[0][0]\n",
    "chobh_idx = np.where(my_stations=='CHOBH')[0][0]\n",
    "\n",
    "print(my_stations[alic1_idx,:])\n",
    "print(my_stations[chobh_idx,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out the latitude longtiude information for the modelled data\n",
    "print(my_sws.coord('X').array)\n",
    "print(my_sws.coord('Y').array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the latitude longitude information from the stations and the modelled grid above, we try to find the nearest grid point in the modelled data\n",
    "# For both station the nearest grid point on the modelled grid is X = -0.75; Y = 51.25\n",
    "# Subselect these two stations from the modelled netcdf file\n",
    "\n",
    "model_sws = my_sws.subspace(X = -0.75, Y = 51.25).squeeze().array #We convert it to a numpy array\n",
    "model_sws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the time information from the first column of my_vwc\n",
    "time = my_vwc[1:,0]\n",
    "print(time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the two stations VWC data for the year 2016 as line plot, also called a spaghetti plot\n",
    "fig = plt.figure(figsize=(18,7))\n",
    "ax=plt.subplot(1,1,1)\n",
    "plt.plot(time, alic1_vwc, color='blue', label='ALIC1_VWC')\n",
    "plt.plot(time, chobh_vwc, color='red', label='CHOBH_VWC')\n",
    "plt.plot(time, model_sws, color='k', label='Model_SWS')\n",
    "plt.ylabel('Soil Water (Percentage)')\n",
    "plt.xticks(time[0::30])\n",
    "plt.xlabel('Time (DD/MM/YYYY)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#For more information about using matplotlib please see https://matplotlib.org/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-slovak",
   "metadata": {},
   "source": [
    "**Discussion**: The SWS and VWC separately show similar variability for 2016, which can be attributed to similar meteorology and geogrpahy of the region, but VWC from the COSMOS stations are still not directly comparable to the SWS data from the model. Both of these variables are indicators for percentage of moisture/water within the soil, but there are some differences between station data and model data, which can mostly be attributed to differences in the variables compared, but can also be attributed to model uncertainity and coarse resolution of the modelled data among many other. In this demonstration we are providing you with tools and methods to compare modelled and observed data (avaialble in different formats) using DataLabs platform. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-cooperation",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"#further_exercises\"></a>\n",
    "### Further Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-material",
   "metadata": {},
   "source": [
    "If you are finished with the rest of the Notebook above, please try the following excercises in the cells given below the exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-detective",
   "metadata": {},
   "source": [
    "1. Please plot line graphs for 2016 for BUNNY and STGHT stations and compare them to the modelled grid point data that they are nearest to.\n",
    "   \n",
    "   HINT: Follow the method demonstrated in the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-arthur",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "animated-photographer",
   "metadata": {},
   "source": [
    "2. Please plot line graphs for daily minimum, maximum and mean VWC for all the COSMOS stations across UK and compare to the minimum, maximum and mean SWS from modelled data over the whole UK for all the days of 2016. Does this comparison seem correct? Is there any area that may not be represented by the stations? What can be done to correct this?\n",
    "   \n",
    "   HINT: You will have to apply numpy minimum, maximum and mean functions across all the rows of VWC data so that you end up with 366 days of output for each function. For the SWS model data, please use collapse function for the whole area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-earth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "qualified-manufacturer",
   "metadata": {},
   "source": [
    "3. Please plot the average VWC for all stations south and east of BUNNY (including BUNNY) and compare it to all the grid points south and east of BUNNY (including the grid point that BUNNY falls on). \n",
    "   \n",
    "   HINT: You can create a python loop to extract data from all the stations that you need. As demonstrated in the cf-python examples Notebook you can use the cf.wi() function to select the range of the X and Y coordinates (south and east of BUNNY) and then take an area mean of the subspaced region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-oxford",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hj-38-nompi",
   "language": "python",
   "name": "hj-38-nompi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
